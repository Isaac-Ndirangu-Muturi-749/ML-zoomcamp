{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ml zoomcamp\n",
    "## week 3 homework\n",
    "## Topic: Machine learning for Classification\n",
    "### name: Isaac Muturi\n",
    "### email: ndirangumuturi749@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we will use the Car price dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv).\n",
    "\n",
    "Or you can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport wget\\n\\nurl = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv'\\n\\nfilename = 'car.csv'\\n\\nwget.download(url, filename)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import wget\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv'\n",
    "\n",
    "filename = 'car.csv'\n",
    "\n",
    "wget.download(url, filename)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep working with the `MSRP` variable, and we'll transform it to a classification task. \n",
    "\n",
    "### Features\n",
    "\n",
    "For the rest of the homework, you'll need to use only these columns:\n",
    "\n",
    "* `Make`,\n",
    "* `Model`,\n",
    "* `Year`,\n",
    "* `Engine HP`,\n",
    "* `Engine Cylinders`,\n",
    "* `Transmission Type`,\n",
    "* `Vehicle Style`,\n",
    "* `highway MPG`,\n",
    "* `city mpg`\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Select only the features from above and transform their names using next line:\n",
    "  ```\n",
    "  data.columns = data.columns.str.replace(' ', '_').str.lower()\n",
    "  ```\n",
    "* Fill in the missing values of the selected features with 0.\n",
    "* Rename `MSRP` variable to `price`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>vehicle_style</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>46135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>40650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>29450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  make       model  year  engine_hp  engine_cylinders transmission_type  \\\n",
       "0  BMW  1 Series M  2011      335.0               6.0            MANUAL   \n",
       "1  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "2  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "3  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "4  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "\n",
       "  vehicle_style  highway_mpg  city_mpg  price  \n",
       "0         Coupe           26        19  46135  \n",
       "1   Convertible           28        19  40650  \n",
       "2         Coupe           28        20  36350  \n",
       "3         Coupe           28        18  29450  \n",
       "4   Convertible           28        18  34500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('car.csv')\n",
    "\n",
    "# Step 2: Select relevant features\n",
    "selected_features = [\n",
    "   'Make', 'Model', 'Year', 'Engine HP', 'Engine Cylinders',\n",
    "   'Transmission Type', 'Vehicle Style', 'highway MPG', 'city mpg',\n",
    "   'MSRP'\n",
    "]\n",
    "\n",
    "df = data[selected_features].copy()  # Create a copy of the selected data\n",
    "\n",
    "# Step 3: Rename columns\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "\n",
    "# Step 4: Fill missing values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Step 5: Rename 'MSRP' to 'price'\n",
    "df.rename(columns={'msrp': 'price'}, inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `transmission_type`?\n",
    "\n",
    "- `AUTOMATIC`\n",
    "- `MANUAL`\n",
    "- `AUTOMATED_MANUAL`\n",
    "- `DIRECT_DRIVE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUTOMATIC'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_transmission = df['transmission_type'].mode()[0]\n",
    "mode_transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset. \n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "\n",
    "What are the two features that have the biggest correlation in this dataset?\n",
    "\n",
    "- `engine_hp` and `year`\n",
    "- `engine_hp` and `engine_cylinders`\n",
    "- `highway_mpg` and `engine_cylinders`\n",
    "- `highway_mpg` and `city_mpg`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'price']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "price        price               1.000000\n",
       "highway_mpg  city_mpg            0.886829\n",
       "engine_hp    engine_cylinders    0.774851\n",
       "             price               0.650095\n",
       "price        engine_cylinders    0.526274\n",
       "year         engine_hp           0.338714\n",
       "highway_mpg  year                0.258240\n",
       "price        year                0.227590\n",
       "city_mpg     year                0.198171\n",
       "year         engine_cylinders   -0.040708\n",
       "city_mpg     price              -0.157676\n",
       "price        highway_mpg        -0.160043\n",
       "engine_hp    highway_mpg        -0.415707\n",
       "city_mpg     engine_hp          -0.424918\n",
       "             engine_cylinders   -0.587306\n",
       "highway_mpg  engine_cylinders   -0.614541\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the numerical features\n",
    "numerical_features = df.select_dtypes(include=['number']).columns.tolist()\n",
    "print(numerical_features)\n",
    "# Create a correlation matrix for numerical features\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "# Find the two features with the biggest correlation\n",
    "max_corr = correlation_matrix.unstack().sort_values(ascending=False).drop_duplicates()\n",
    "max_corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Make `price` binary\n",
    "\n",
    "* Now we need to turn the `price` variable from numeric into a binary format.\n",
    "* Let's create a variable `above_average` which is `1` if the `price` is above its mean value and `0` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: above_average, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean of the 'price' variable\n",
    "price_mean = df['price'].mean()\n",
    "\n",
    "# Create the 'above_average' binary variable\n",
    "df['above_average'] = (df['price'] > price_mean).astype(int)\n",
    "df.above_average.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "* Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "* Make sure that the target value (`price`) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the features (X) and target variable (y)\n",
    "X = df.drop(columns=['price', 'above_average'])\n",
    "y = df['above_average']\n",
    "\n",
    "# Split the data into training (60%), validation (20%), and test (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "* Calculate the mutual information score between `above_average` and other categorical variables in our dataset. \n",
    "  Use the training set only.\n",
    "* Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the lowest mutual information score?\n",
    "  \n",
    "- `make`\n",
    "- `model`\n",
    "- `transmission_type`\n",
    "- `vehicle_style`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable with the lowest mutual information score: transmission_type\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Calculate the mutual information scores between 'above_average' and categorical variables\n",
    "categorical_columns = df.select_dtypes(include='object').columns.tolist()\n",
    "X_categorical = df[categorical_columns]\n",
    "y_above_average = df['above_average']\n",
    "\n",
    "mutual_info_scores = {}\n",
    "\n",
    "for col in X_categorical.columns:\n",
    "    score = mutual_info_score(y_above_average, X_categorical[col])\n",
    "    mutual_info_scores[col] = round(score, 2)\n",
    "\n",
    "# Find the variable with the lowest mutual information score\n",
    "lowest_mi_variable = min(mutual_info_scores, key=mutual_info_scores.get)\n",
    "\n",
    "# Print the variable with the lowest mutual information score\n",
    "print(\"Variable with the lowest mutual information score:\", lowest_mi_variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - `model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)`\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.60\n",
    "- 0.72\n",
    "- 0.84\n",
    "- 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation dataset: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "X_train_dict = X_train.to_dict(orient='records')\n",
    "X_val_dict = X_val.to_dict(orient='records')\n",
    "\n",
    "# Initialize DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "# Transform features using DictVectorizer (for training set)\n",
    "X_train_encoded = vectorizer.fit_transform(X_train_dict)\n",
    "# Transform features using DictVectorizer (for validation set)\n",
    "X_val_encoded = vectorizer.transform(X_val_dict)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_encoded, y_train)\n",
    "# Make predictions on the validation data\n",
    "y_pred = model.predict(X_val_encoded)\n",
    "\n",
    "# Calculate the accuracy on the validation dataset\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "# Round the accuracy to 2 decimal digits\n",
    "rounded_accuracy = round(accuracy, 2)\n",
    "print(\"Accuracy on the validation dataset:\", rounded_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "* Let's find the least useful feature using the *feature elimination* technique.\n",
    "* Train a model with all these features (using the same parameters as in Q4).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `year`\n",
    "- `engine_hp`\n",
    "- `transmission_type`\n",
    "- `city_mpg`\n",
    "\n",
    "> **Note**: the difference doesn't have to be positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature with the smallest absolute difference: year\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Create a logistic regression model with all features\n",
    "model_with_all_features = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "# Fit the model on the training data with all features\n",
    "model_with_all_features.fit(X_train_encoded, y_train)\n",
    "y_predd = model_with_all_features.predict(X_val_encoded)\n",
    "# Calculate the accuracy with all features\n",
    "accuracy_with_all_features = accuracy_score(y_val, y_predd)\n",
    "\n",
    "# Initialize a dictionary to store feature elimination results\n",
    "feature_elimination_results = {}\n",
    "# Loop through each feature and calculate the accuracy without it\n",
    "for feature_idx, feature in enumerate(X_train.columns):\n",
    "    # Create a copy of the training data without the current feature\n",
    "    X_train_without_feature_encoded = np.delete(X_train_encoded, feature_idx, axis=1)\n",
    "    X_val_without_feature_encoded = np.delete(X_val_encoded, feature_idx, axis=1)\n",
    "    model_without_feature = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "    model_without_feature.fit(X_train_without_feature_encoded, y_train)\n",
    "    y_predd_without_feature = model_without_feature.predict(X_val_without_feature_encoded)\n",
    "    # Calculate the accuracy without the feature\n",
    "    accuracy_without_feature = accuracy_score(y_val, y_predd_without_feature)\n",
    "    # Calculate the difference in accuracy\n",
    "    accuracy_difference = accuracy_with_all_features - accuracy_without_feature\n",
    "    # Store the result in the dictionary\n",
    "    feature_elimination_results[feature] = accuracy_difference\n",
    "\n",
    "# Identify the feature with the smallest absolute difference\n",
    "smallest_difference_feature = min(feature_elimination_results, key=lambda x: abs(feature_elimination_results[x]))\n",
    "print(\"Feature with the smallest absolute difference:\", smallest_difference_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'make': -0.013428451531682706,\n",
       " 'model': -0.01888375996642888,\n",
       " 'year': 0.002937473772555599,\n",
       " 'engine_hp': -0.01720520352496857,\n",
       " 'engine_cylinders': -0.017624842635333593,\n",
       " 'transmission_type': -0.013428451531682706,\n",
       " 'vehicle_style': -0.01552664708350815,\n",
       " 'highway_mpg': -0.015107007973143127,\n",
       " 'city_mpg': -0.015946286193873282}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_elimination_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "* For this question, we'll see how to use a linear regression model from Scikit-Learn.\n",
    "* We'll need to use the original column `price`. Apply the logarithmic transformation to this column.\n",
    "* Fit the Ridge regression model on the training data with a solver `'sag'`. Set the seed to `42`.\n",
    "* This model also has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`.\n",
    "* Round your RMSE scores to 3 decimal digits.\n",
    "\n",
    "Which of these alphas leads to the best RMSE on the validation set?\n",
    "\n",
    "- 0\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `alpha`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ndira\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\ndira\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\ndira\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\ndira\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ndira\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the features (X) and target variable (y)\n",
    "X = df.drop(columns=['price', 'above_average'])\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training (60%), validation (20%), and test (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Apply logarithmic transformation to the target variable\n",
    "y_train = np.log1p(y_train)\n",
    "y_val = np.log1p(y_val)\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "X_train_dict = X_train.to_dict(orient='records')\n",
    "X_val_dict = X_val.to_dict(orient='records')\n",
    "\n",
    "# Initialize DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "# Transform features using DictVectorizer (for training set)\n",
    "X_train_encoded = vectorizer.fit_transform(X_train_dict)\n",
    "# Transform features using DictVectorizer (for validation set)\n",
    "X_val_encoded = vectorizer.transform(X_val_dict)\n",
    "\n",
    "\n",
    "# Initialize Ridge regression model with different alphas\n",
    "alphas = [0, 0.01, 0.1, 1, 10]\n",
    "best_rmse = float('inf')\n",
    "best_alpha = None\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Create and fit Ridge regression model\n",
    "    model = Ridge(alpha=alpha, solver='sag', random_state=42)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val_encoded)\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    # Update best RMSE and alpha if necessary\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(\"Best alpha:\", best_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Best alpha:\", best_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow me on Twitter 🐦, connect with me on LinkedIn 🔗, and check out my GitHub 🐙. You won't be disappointed!\n",
    "\n",
    "👉 Twitter: https://twitter.com/NdiranguMuturi1  \n",
    "👉 LinkedIn: https://www.linkedin.com/in/isaac-muturi-3b6b2b237  \n",
    "👉 GitHub: https://github.com/Isaac-Ndirangu-Muturi-749   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
