{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012ac7e0",
   "metadata": {},
   "source": [
    "# ml zoomcamp\n",
    "## week 8 homework\n",
    "## Topic: Neural Networks and Deep Learning\n",
    "### name: Isaac Muturi\n",
    "### email: ndirangumuturi749@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43cfb1",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we'll build a model for predicting if we have an image of a bee or a wasp. \n",
    "For this, we will use the \"Bee or Wasp?\" dataset that was obtained from [Kaggle](https://www.kaggle.com/datasets/jerzydziewierz/bee-vs-wasp) and slightly rebuilt. \n",
    "\n",
    "You can download the dataset for this homework from [here](https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip):\n",
    "\n",
    "```bash\n",
    "wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "unzip data.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8818fc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !wget -q https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "# !unzip data.zip\n",
    "# !rm data.zip\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73efbc88",
   "metadata": {},
   "source": [
    "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch. \n",
    "\n",
    "> **Note:** you will need an environment with a GPU for this homework. We recommend to use [Saturn Cloud](https://bit.ly/saturn-mlzoomcamp). \n",
    "> You can also use a computer without a GPU (e.g. your laptop), but it will be slower.\n",
    "\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "The dataset contains around 2500 images of bees and around 2100 images of wasps. \n",
    "\n",
    "The dataset contains separate folders for training and test sets. \n",
    "\n",
    "\n",
    "### Model\n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Next, create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`\n",
    "\n",
    "For clarification about kernel size and max pooling, check [Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9db550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 20:48:59.123662: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-16 20:49:00.667436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 20:49:00.673670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 20:49:00.673879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 20:49:00.674332: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 20:49:00.674655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 20:49:00.674864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 20:49:00.675026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 20:49:01.248909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 20:49:01.249139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 20:49:01.249304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 20:49:01.249469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13794 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "\n",
    "# Add max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 64 neurons and 'relu' activation\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# Output layer with 1 neuron and appropriate activation for binary classification (e.g., 'sigmoid')\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Create an optimizer with SGD\n",
    "optimizer = SGD(learning_rate=0.002, momentum=0.8)\n",
    "\n",
    "# Compile the model with SGD optimizer\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825859a2",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "* `mean squared error`\n",
    "* `binary crossentropy`\n",
    "* `categorical crossentropy`\n",
    "* `cosine similarity`\n",
    "\n",
    "> **Note:** since we specify an activation for the output layer, we don't need to set `from_logits=True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eaa452",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the `summary` method for that. \n",
    "\n",
    "* 1 \n",
    "* 65\n",
    "* 896\n",
    "* 11214912"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294ae93",
   "metadata": {},
   "source": [
    "### Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* When reading the data from train/test directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
    "* Use `batch_size=20`\n",
    "* Use `shuffle=True` for both training and test sets. \n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b734cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 20:49:02.703254: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-11-16 20:49:03.293914: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-16 20:49:03.294368: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-16 20:49:03.294405: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-11-16 20:49:03.294852: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-16 20:49:03.294942: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 10s 42ms/step - loss: 0.6723 - accuracy: 0.5646 - val_loss: 0.6225 - val_accuracy: 0.6645\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 7s 41ms/step - loss: 0.6291 - accuracy: 0.6494 - val_loss: 0.5981 - val_accuracy: 0.6721\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.5809 - accuracy: 0.6957 - val_loss: 0.5597 - val_accuracy: 0.7026\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.5499 - accuracy: 0.7240 - val_loss: 0.5527 - val_accuracy: 0.7440\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.5092 - accuracy: 0.7615 - val_loss: 0.5375 - val_accuracy: 0.7375\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.4911 - accuracy: 0.7811 - val_loss: 0.5454 - val_accuracy: 0.7505\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 8s 41ms/step - loss: 0.4854 - accuracy: 0.7778 - val_loss: 0.5431 - val_accuracy: 0.7429\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 8s 41ms/step - loss: 0.4608 - accuracy: 0.8001 - val_loss: 0.5068 - val_accuracy: 0.7560\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 8s 41ms/step - loss: 0.4278 - accuracy: 0.8178 - val_loss: 0.5123 - val_accuracy: 0.7614\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 7s 40ms/step - loss: 0.4115 - accuracy: 0.8278 - val_loss: 0.5370 - val_accuracy: 0.7407\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Specify the directory for training and test data\n",
    "train_generator = train_datagen.flow_from_directory('data/train',\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=20, \n",
    "                                                    class_mode='binary'\n",
    "                                                   )\n",
    "test_generator = test_datagen.flow_from_directory('data/test', \n",
    "                                                  target_size=(150, 150), \n",
    "                                                  batch_size=20, \n",
    "                                                  class_mode='binary'\n",
    "                                                 )\n",
    "\n",
    "#train the model\n",
    "history = model.fit(train_generator,\n",
    "          epochs=10,\n",
    "          validation_data=test_generator\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400f9c3",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "* 0.20\n",
    "* 0.40\n",
    "* 0.60\n",
    "* 0.80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba6807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7696491777896881"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbee54",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "* 0.031\n",
    "* 0.061\n",
    "* 0.091\n",
    "* 0.131\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada26de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08098069949361864"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c95ff6",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations. \n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* `rotation_range=50,`\n",
    "* `width_shift_range=0.1,`\n",
    "* `height_shift_range=0.1,`\n",
    "* `zoom_range=0.1,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f259528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.4966 - accuracy: 0.7696 - val_loss: 0.4766 - val_accuracy: 0.7756\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.4865 - accuracy: 0.7732 - val_loss: 0.4882 - val_accuracy: 0.7680\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.4824 - accuracy: 0.7822 - val_loss: 0.4594 - val_accuracy: 0.7887\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.4757 - accuracy: 0.7849 - val_loss: 0.4880 - val_accuracy: 0.7680\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.4729 - accuracy: 0.7832 - val_loss: 0.4734 - val_accuracy: 0.7821\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.4752 - accuracy: 0.7775 - val_loss: 0.4846 - val_accuracy: 0.7582\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.4642 - accuracy: 0.7835 - val_loss: 0.4560 - val_accuracy: 0.7887\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.4698 - accuracy: 0.7900 - val_loss: 0.4561 - val_accuracy: 0.7865\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.4605 - accuracy: 0.7900 - val_loss: 0.4421 - val_accuracy: 0.8050\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.4639 - accuracy: 0.7876 - val_loss: 0.4848 - val_accuracy: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator with augmentations\n",
    "train_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator_augmented = train_datagen_augmented.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'  # Use 'binary' for binary classification\n",
    ")\n",
    "\n",
    "# use augmented generator for training\n",
    "history = model.fit(\n",
    "    train_generator_augmented,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator  # 'test_generator' doesnt change\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7277f",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "> **Note:** make sure you don't re-create the model - we want to continue training the model\n",
    "we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "* 0.18\n",
    "* 0.48\n",
    "* 0.78\n",
    "* 0.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dafaffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4709283709526062"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78aaa5",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?\n",
    "\n",
    "* 0.38\n",
    "* 0.58\n",
    "* 0.78\n",
    "* 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041a9cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806100249290466"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_accuracy'][5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7ec92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 16 20:58:36 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.8     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    31W /  70W |  14631MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
